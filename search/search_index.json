{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"KNN (K-NEAREST NEIGHBOUR) \u00b6 Apa itu K-NN ?. \u00b6 \u200b K-NN (K-Nearest Neighbor) adalah suatu metode yang menggunakan algoritma, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. tujuan dari algoritma adalah untuk mengklasifikasikan obyek baru berdasarkan atribut dan training sample. Algortitma K-NN \u00b6 \u200b Algoritma metode K-NN bekerja berdasarkan jarak terpendek dari query instance ke training sample. Training sample diproyeksi keruang berdimensi banyak, dimana masing-masing dimensi mempresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi training sample. Dekat atau jauhnya tetangga, biasanya dihitung berdasarkan Euclidean Distance. Langkah-langkah yang digunakan dalam metode K-Nearest Neighbor : Menentukan parameter \"K\" (jumlah tetangga paling dekat). Hitung kuadrat jarak euclidean pada masing-masing obyek terhadap data sample yang diberikan. Urutkan jarak tersebut dan tentukan tetangga yang terdekat berdasarkan jarak minimum ke-K . Tentukan kategori dari tetangga terdekat. Gunakan kategori mayoritas dari tetangga yang terdekat sebagai nilai prediksi dari data yang baru. Contoh perhitungan numerik \u00b6 \u200b \u200b Data diatas terdiri dari 2 atribut dengan skala kuantitatif X1 dan X2 serta 2 kelas yaitu Bagus dan Jelek. Jika terdapat data baru dengan nilai X1 = 3 dan X2 = 7. Kita gunakan algoritma K-NN untuk melakukan prediksi termasuk klasifikasi apa (Bagus atau Jelek) data baru ini ? Tentukan parameter K = jumlah banyaknya tetangga terdekat. Misalnya K= 3 . Hitung jarak antara data baru dan semua data yang ada di data training. Misal menggunakan square distance dari jarak antara data baru dengan semua data yang ada di data training. Urtkan jarak tersebut dan tentukan tetangga mana yang terdekat berdasarkan jarak minimum ke-K Periksa kelas dari tetangga terdekat Gunakan kategori mayoritas untuk memprediksi data yang baru. Kita mempunyai 2 kategori Bagus dan 1 kategori Jelek, karena 2>1 maka kita simpulkan bahwa kertas tissue baru yang memiliki X1 = 3 dan X2 = 7 termasuk dalam kategori Bagus. \u200b Untuk lebih mudah mengerjakan K-NN dengan jumlah data yang banyak kita bisa menggunakan kode-kode program seperti dibawah ini. Step 1: Import data yang yang dibutuhkan dan periksa fitur-fitur \u200b Import fungsi load_iris dari datasets module dan buat sebuah iris bunch object (bunch adalah scikit learn adalah tipe objec khusus untuk menyimpan dataset dan atributnya) #Import load_iris function dari datasets module from sklearn.datasets import load_iris #Create bunch object containing datasets and its attributes. iris = load_iris() type(iris) #Print the iris data iris.data #Print of 4 features (column names) print(iris.feature_names) #Integers representing the species: 0=setosa, 1=versicolor, 2=Virginica print(iris.target) #3 classes of target print(iris.target_names) print(type(iris.data)) print(type(iris.target)) #we have a total of 150 observation and 4 features print(iris.data.shape) #splitting the data into training and test sets (80:20) from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=4) #shape of train and test objects print(X_train.shape) print(X_test.shape) #shape of new y objects print(y_train.shape) print(y_test.shape) <b>Output</b> \u200b \u200b Dalam contoh kami, kami menciptakan sebuah instance (' KNN ') dari kelas ' Ktetangga Sclassifer ', dengan kata lain kami telah menciptakan sebuah objek yang disebut ' KNN ' yang tahu bagaimana melakukan KNN klasifikasi setelah kami menyediakan data. Parameter ' n_neighbors ' adalah parameter tuning/Hyper parameter (k). Semua parameter lainnya diatur ke nilai default. \u200b Metode ' Fit ' digunakan untuk melatih model pada data pelatihan (X_train, y_train) dan ' memprediksi ' metode untuk melakukan pengujian pada pengujian data (X_test). Memilih nilai optimal K sangat penting, jadi kami cocok dan menguji model untuk nilai yang berbeda untuk K (dari 1 sampai 45) menggunakan untuk loop dan merekam akurasi pengujian KNN dalam variabel (Skor). #Import the KNeighborsClassifier class from sclearn from sklearn.neighbors import KNeighborsClassifier clf=KNeighborsClassifier(n_neighbors=3).fit(X_train,y_train) from sklearn.metrics import accuracy_score print(\"accuracy is \") print(accuracy_score(y_test,clf.predict(X_test))) import matplotlib.pyplot as plt accuracy_values=[] #Try running from k=1 trhough 45 and record testing accuracy k_range = range(1,45) scores = {} scores_list = [] for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) scores[k] = accuracy_score(y_test,y_pred) scores_list.append(accuracy_score(y_test,y_pred)) import numpy as np accuracy_values=np.array(accuracy_values) #plot the relationship between k and the testing accuracy plt.plot(k_range,scores_list) plt.xlabel('Value of k for KNN') plt.ylabel('Testing Accuracy') Output \u200b Jadi untuk model terakhir, kita dapat memilih nilai yang optimal K antara 3 dan 19, antara 22 dan 25 yang merupakan nilai tertinggi dari testing accuracy. Mungkin sampai disini pembahasan dari Knowladge of KNN terima kasih.....","title":"K-NN"},{"location":"#knn-k-nearest-neighbour","text":"","title":"KNN (K-NEAREST NEIGHBOUR)"},{"location":"#apa-itu-k-nn","text":"\u200b K-NN (K-Nearest Neighbor) adalah suatu metode yang menggunakan algoritma, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. tujuan dari algoritma adalah untuk mengklasifikasikan obyek baru berdasarkan atribut dan training sample.","title":"Apa itu K-NN ?."},{"location":"#algortitma-k-nn","text":"\u200b Algoritma metode K-NN bekerja berdasarkan jarak terpendek dari query instance ke training sample. Training sample diproyeksi keruang berdimensi banyak, dimana masing-masing dimensi mempresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi training sample. Dekat atau jauhnya tetangga, biasanya dihitung berdasarkan Euclidean Distance. Langkah-langkah yang digunakan dalam metode K-Nearest Neighbor : Menentukan parameter \"K\" (jumlah tetangga paling dekat). Hitung kuadrat jarak euclidean pada masing-masing obyek terhadap data sample yang diberikan. Urutkan jarak tersebut dan tentukan tetangga yang terdekat berdasarkan jarak minimum ke-K . Tentukan kategori dari tetangga terdekat. Gunakan kategori mayoritas dari tetangga yang terdekat sebagai nilai prediksi dari data yang baru.","title":"Algortitma K-NN"},{"location":"#contoh-perhitungan-numerik","text":"\u200b \u200b Data diatas terdiri dari 2 atribut dengan skala kuantitatif X1 dan X2 serta 2 kelas yaitu Bagus dan Jelek. Jika terdapat data baru dengan nilai X1 = 3 dan X2 = 7. Kita gunakan algoritma K-NN untuk melakukan prediksi termasuk klasifikasi apa (Bagus atau Jelek) data baru ini ? Tentukan parameter K = jumlah banyaknya tetangga terdekat. Misalnya K= 3 . Hitung jarak antara data baru dan semua data yang ada di data training. Misal menggunakan square distance dari jarak antara data baru dengan semua data yang ada di data training. Urtkan jarak tersebut dan tentukan tetangga mana yang terdekat berdasarkan jarak minimum ke-K Periksa kelas dari tetangga terdekat Gunakan kategori mayoritas untuk memprediksi data yang baru. Kita mempunyai 2 kategori Bagus dan 1 kategori Jelek, karena 2>1 maka kita simpulkan bahwa kertas tissue baru yang memiliki X1 = 3 dan X2 = 7 termasuk dalam kategori Bagus. \u200b Untuk lebih mudah mengerjakan K-NN dengan jumlah data yang banyak kita bisa menggunakan kode-kode program seperti dibawah ini. Step 1: Import data yang yang dibutuhkan dan periksa fitur-fitur \u200b Import fungsi load_iris dari datasets module dan buat sebuah iris bunch object (bunch adalah scikit learn adalah tipe objec khusus untuk menyimpan dataset dan atributnya) #Import load_iris function dari datasets module from sklearn.datasets import load_iris #Create bunch object containing datasets and its attributes. iris = load_iris() type(iris) #Print the iris data iris.data #Print of 4 features (column names) print(iris.feature_names) #Integers representing the species: 0=setosa, 1=versicolor, 2=Virginica print(iris.target) #3 classes of target print(iris.target_names) print(type(iris.data)) print(type(iris.target)) #we have a total of 150 observation and 4 features print(iris.data.shape) #splitting the data into training and test sets (80:20) from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.2,random_state=4) #shape of train and test objects print(X_train.shape) print(X_test.shape) #shape of new y objects print(y_train.shape) print(y_test.shape) <b>Output</b> \u200b \u200b Dalam contoh kami, kami menciptakan sebuah instance (' KNN ') dari kelas ' Ktetangga Sclassifer ', dengan kata lain kami telah menciptakan sebuah objek yang disebut ' KNN ' yang tahu bagaimana melakukan KNN klasifikasi setelah kami menyediakan data. Parameter ' n_neighbors ' adalah parameter tuning/Hyper parameter (k). Semua parameter lainnya diatur ke nilai default. \u200b Metode ' Fit ' digunakan untuk melatih model pada data pelatihan (X_train, y_train) dan ' memprediksi ' metode untuk melakukan pengujian pada pengujian data (X_test). Memilih nilai optimal K sangat penting, jadi kami cocok dan menguji model untuk nilai yang berbeda untuk K (dari 1 sampai 45) menggunakan untuk loop dan merekam akurasi pengujian KNN dalam variabel (Skor). #Import the KNeighborsClassifier class from sclearn from sklearn.neighbors import KNeighborsClassifier clf=KNeighborsClassifier(n_neighbors=3).fit(X_train,y_train) from sklearn.metrics import accuracy_score print(\"accuracy is \") print(accuracy_score(y_test,clf.predict(X_test))) import matplotlib.pyplot as plt accuracy_values=[] #Try running from k=1 trhough 45 and record testing accuracy k_range = range(1,45) scores = {} scores_list = [] for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) scores[k] = accuracy_score(y_test,y_pred) scores_list.append(accuracy_score(y_test,y_pred)) import numpy as np accuracy_values=np.array(accuracy_values) #plot the relationship between k and the testing accuracy plt.plot(k_range,scores_list) plt.xlabel('Value of k for KNN') plt.ylabel('Testing Accuracy') Output \u200b Jadi untuk model terakhir, kita dapat memilih nilai yang optimal K antara 3 dan 19, antara 22 dan 25 yang merupakan nilai tertinggi dari testing accuracy. Mungkin sampai disini pembahasan dari Knowladge of KNN terima kasih.....","title":"Contoh perhitungan numerik"},{"location":"DecisionTree/","text":"License \u00b6 MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Decision Tree"},{"location":"DecisionTree/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"biodata/","text":"BIODATA \u00b6 Nama : Erika Hujjatuna Annisak NIM : 170441100108","title":"\t\t\t\t\tBIODATA</small>"},{"location":"biodata/#biodata","text":"Nama : Erika Hujjatuna Annisak NIM : 170441100108","title":"BIODATA"}]}